{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e412c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader # Importing PDF loader from Langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # Importing text splitter from Langchain\n",
    "from langchain.embeddings import OpenAIEmbeddings # Importing OpenAI embeddings from Langchain\n",
    "from langchain.schema import Document # Importing Document schema from Langchain\n",
    "from langchain.vectorstores.chroma import Chroma # Importing Chroma vector store from Langchain\n",
    "from dotenv import load_dotenv # Importing dotenv to get API key from .env file\n",
    "from langchain.chat_models import ChatOpenAI # Import OpenAI LLM\n",
    "import os # Importing os module for operating system functionalities\n",
    "import shutil # Importing shutil module for high-level file operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bbd1395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134212_FirstRanker.com.pdf', 'page': 0}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134212_FirstRanker.com.pdf', 'page': 1}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134212_FirstRanker.com.pdf', 'page': 2}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134212_FirstRanker.com.pdf', 'page': 3}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134212_FirstRanker.com.pdf', 'page': 4}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134212_FirstRanker.com.pdf', 'page': 5}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134219_FirstRanker.com.pdf', 'page': 0}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134219_FirstRanker.com.pdf', 'page': 1}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134219_FirstRanker.com.pdf', 'page': 2}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134219_FirstRanker.com.pdf', 'page': 3}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134219_FirstRanker.com.pdf', 'page': 4}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134219_FirstRanker.com.pdf', 'page': 5}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134219_FirstRanker.com.pdf', 'page': 6}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134219_FirstRanker.com.pdf', 'page': 7}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134219_FirstRanker.com.pdf', 'page': 8}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134231_FirstRanker.com.pdf', 'page': 0}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134231_FirstRanker.com.pdf', 'page': 1}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134231_FirstRanker.com.pdf', 'page': 2}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134231_FirstRanker.com.pdf', 'page': 3}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A213423_FirstRanker.com.pdf', 'page': 0}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A213423_FirstRanker.com.pdf', 'page': 1}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A213423_FirstRanker.com.pdf', 'page': 2}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A213423_FirstRanker.com.pdf', 'page': 3}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A213423_FirstRanker.com.pdf', 'page': 4}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A213423_FirstRanker.com.pdf', 'page': 5}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A213423_FirstRanker.com.pdf', 'page': 6}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A213423_FirstRanker.com.pdf', 'page': 7}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134272_FirstRanker.com.pdf', 'page': 0}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134272_FirstRanker.com.pdf', 'page': 1}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134272_FirstRanker.com.pdf', 'page': 2}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134272_FirstRanker.com.pdf', 'page': 3}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n'), Document(metadata={'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134272_FirstRanker.com.pdf', 'page': 4}, page_content='www.FirstRanker.com\\nwww.FirstRanker.com www.FirstRanker.com\\nwww.FirstRanker.com\\n')]\n"
     ]
    }
   ],
   "source": [
    "# Directory to your pdf files:\n",
    "DATA_PATH = \"C:/Users/dharn/Downloads/project_documents\"\n",
    "def load_documents():\n",
    "  \"\"\"\n",
    "  Load PDF documents from the specified directory using PyPDFDirectoryLoader.\n",
    "  Returns:\n",
    "  List of Document objects: Loaded PDF documents represented as Langchain\n",
    "                                                          Document objects.\n",
    "  \"\"\"\n",
    "  # Initialize PDF loader with specified directory\n",
    "  document_loader = PyPDFDirectoryLoader(DATA_PATH) \n",
    "  # Load PDF documents and return them as a list of Document objects\n",
    "  return document_loader.load() \n",
    "  db.get()\n",
    "\n",
    "documents = load_documents() # Call the function\n",
    "# Inspect the contents of the first document as well as metadata\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3a5f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(documents: list[Document]):\n",
    "  \"\"\"\n",
    "  Split the text content of the given list of Document objects into smaller chunks.\n",
    "  Args:\n",
    "    documents (list[Document]): List of Document objects containing text content to split.\n",
    "  Returns:\n",
    "    list[Document]: List of Document objects representing the split text chunks.\n",
    "  \"\"\"\n",
    "  # Initialize text splitter with specified parameters\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300, # Size of each chunk in characters\n",
    "    chunk_overlap=100, # Overlap between consecutive chunks\n",
    "    length_function=len, # Function to compute the length of the text\n",
    "    add_start_index=True, # Flag to add start index to each chunk\n",
    "  )\n",
    "\n",
    "  # Split documents into smaller chunks using text splitter\n",
    "  chunks = text_splitter.split_documents(documents)\n",
    "  print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "  # Print example of page content and metadata for a chunk\n",
    "  document = chunks[0]\n",
    "  print(document.page_content)\n",
    "  print(document.metadata)\n",
    "\n",
    "  return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68d1274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory to save Chroma database\n",
    "CHROMA_PATH = \"chroma\"\n",
    "def save_to_chroma(chunks: list[Document]):\n",
    "  \"\"\"\n",
    "  Save the given list of Document objects to a Chroma database.\n",
    "  Args:\n",
    "  chunks (list[Document]): List of Document objects representing text chunks to save.\n",
    "  Returns:\n",
    "  None\n",
    "  \"\"\"\n",
    "\n",
    "  # Clear out the existing database directory if it exists\n",
    "  if os.path.exists(CHROMA_PATH):\n",
    "    shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "  # Create a new Chroma database from the documents using OpenAI embeddings\n",
    "  db = Chroma.from_documents(\n",
    "    chunks,\n",
    "    OpenAIEmbeddings(),\n",
    "    persist_directory=CHROMA_PATH\n",
    "  )\n",
    "\n",
    "  # Persist the database to disk\n",
    "  db.persist()\n",
    "  print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6f523bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 32 documents into 32 chunks.\n",
      "www.FirstRanker.com\n",
      "www.FirstRanker.com www.FirstRanker.com\n",
      "www.FirstRanker.com\n",
      "{'source': 'C:\\\\Users\\\\dharn\\\\Downloads\\\\project_documents\\\\frdA310821A2134212_FirstRanker.com.pdf', 'page': 0, 'start_index': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dharn\\AppData\\Local\\Temp\\ipykernel_19232\\3023069566.py:19: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  OpenAIEmbeddings(),\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m load_dotenv()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Generate the data store\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mgenerate_data_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m, in \u001b[0;36mgenerate_data_store\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m documents \u001b[38;5;241m=\u001b[39m load_documents() \u001b[38;5;66;03m# Load documents from a source\u001b[39;00m\n\u001b[0;32m      6\u001b[0m chunks \u001b[38;5;241m=\u001b[39m split_text(documents) \u001b[38;5;66;03m# Split documents into manageable chunks\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43msave_to_chroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m, in \u001b[0;36msave_to_chroma\u001b[1;34m(chunks)\u001b[0m\n\u001b[0;32m     14\u001b[0m   shutil\u001b[38;5;241m.\u001b[39mrmtree(CHROMA_PATH)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create a new Chroma database from the documents using OpenAI embeddings\u001b[39;00m\n\u001b[0;32m     17\u001b[0m db \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[0;32m     18\u001b[0m   chunks,\n\u001b[1;32m---> 19\u001b[0m   \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     20\u001b[0m   persist_directory\u001b[38;5;241m=\u001b[39mCHROMA_PATH\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Persist the database to disk\u001b[39;00m\n\u001b[0;32m     24\u001b[0m db\u001b[38;5;241m.\u001b[39mpersist()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     emit_warning()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\main.py:193\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    192\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/value_error"
     ]
    }
   ],
   "source": [
    "def generate_data_store():\n",
    "  \"\"\"\n",
    "  Function to generate vector database in chroma from documents.\n",
    "  \"\"\"\n",
    "  documents = load_documents() # Load documents from a source\n",
    "  chunks = split_text(documents) # Split documents into manageable chunks\n",
    "  save_to_chroma(chunks) # Save the processed data to a data store\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "# Generate the data store\n",
    "generate_data_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "395a8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Explain Bood supply of brain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "190e433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    " - -\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f226c5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m formatted_response, response_text\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Let's call our function we have defined\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m formatted_response, response_text \u001b[38;5;241m=\u001b[39m \u001b[43mquery_rag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# and finally, inspect our final response!\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_text)\n",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m, in \u001b[0;36mquery_rag\u001b[1;34m(query_text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mQuery a Retrieval-Augmented Generation (RAG) system using Chroma database and OpenAI.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m  - response_text (str): The generated response text.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# YOU MUST - Use same embedding function as before\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m embedding_function \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Prepare the database\u001b[39;00m\n\u001b[0;32m     14\u001b[0m db \u001b[38;5;241m=\u001b[39m Chroma(persist_directory\u001b[38;5;241m=\u001b[39mCHROMA_PATH, embedding_function\u001b[38;5;241m=\u001b[39membedding_function)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     emit_warning()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\main.py:193\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    192\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/value_error"
     ]
    }
   ],
   "source": [
    "def query_rag(query_text):\n",
    "  \"\"\"\n",
    "  Query a Retrieval-Augmented Generation (RAG) system using Chroma database and OpenAI.\n",
    "  Args:\n",
    "    - query_text (str): The text to query the RAG system with.\n",
    "  Returns:\n",
    "    - formatted_response (str): Formatted response including the generated text and sources.\n",
    "    - response_text (str): The generated response text.\n",
    "  \"\"\"\n",
    "  # YOU MUST - Use same embedding function as before\n",
    "  embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "  # Prepare the database\n",
    "  db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "  \n",
    "  # Retrieving the context from the DB using similarity search\n",
    "  results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "\n",
    "  # Check if there are any matching results or if the relevance score is too low\n",
    "  if len(results) == 0 or results[0][1] < 0.7:\n",
    "    print(f\"Unable to find matching results.\")\n",
    "\n",
    "  # Combine context from matching documents\n",
    "  context_text = \"\\n\\n - -\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    " \n",
    "  # Create prompt template using context and query text\n",
    "  prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "  prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "  \n",
    "  # Initialize OpenAI chat model\n",
    "  model = ChatOpenAI()\n",
    "\n",
    "  # Generate response text based on the prompt\n",
    "  response_text = model.predict(prompt)\n",
    " \n",
    "   # Get sources of the matching documents\n",
    "  sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    " \n",
    "  # Format and return response including generated text and sources\n",
    "  formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "  return formatted_response, response_text\n",
    "\n",
    "# Let's call our function we have defined\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "# and finally, inspect our final response!\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865516f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
